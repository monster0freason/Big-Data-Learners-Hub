{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import os\n",
        "\n",
        "def clean_csv_for_spark(input_filepath, output_filepath):\n",
        "    \"\"\"\n",
        "    Reads a CSV file, cleans and wraps the 'description' column, and saves the result\n",
        "    to a new CSV file.\n",
        "\n",
        "    Args:\n",
        "        input_filepath (str): The path to the original CSV file.\n",
        "        output_filepath (str): The path to save the cleaned CSV file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(input_filepath):\n",
        "        print(f\"Error: Input file not found at '{input_filepath}'\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(input_filepath)\n",
        "\n",
        "        if 'description' not in df.columns:\n",
        "            print(\"Error: 'description' column not found in the CSV.\")\n",
        "            return\n",
        "\n",
        "        def clean_and_wrap_text(text):\n",
        "            \"\"\"Cleans a text string and wraps it with '$$$'.\"\"\"\n",
        "            if not isinstance(text, str):\n",
        "                return \"\"\n",
        "\n",
        "            text = text.replace('\"', \"'\")\n",
        "            text = re.sub(r'[\\n\\t\\r]', ' ', text)\n",
        "            text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "            if text:\n",
        "                return f\"$$${text}$$$\"\n",
        "            return \"\"\n",
        "\n",
        "        df['description'] = df['description'].apply(clean_and_wrap_text)\n",
        "        df['cast'] = df['cast'].apply(clean_and_wrap_text)\n",
        "        df['listed_in'] = df['listed_in'].apply(clean_and_wrap_text)\n",
        "        df['title'] = df['title'].apply(clean_and_wrap_text)\n",
        "        df['director'] = df['director'].apply(clean_and_wrap_text)\n",
        "\n",
        "\n",
        "\n",
        "        df.to_csv(output_filepath, index=False, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "        print(f\"✅ Successfully cleaned and wrapped the 'description' column!\")\n",
        "        print(f\"Cleaned data saved to: '{output_filepath}'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the process: {e}\")\n",
        "\n",
        "# Define the input and output file names\n",
        "original_file = 'netflix_titles.csv'\n",
        "cleaned_file = 'part_1_cleaned_and_wrapped.csv'\n",
        "\n",
        "# Run the cleaning and wrapping function\n",
        "clean_csv_for_spark(original_file, cleaned_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xNutt9crmsj",
        "outputId": "a7c86d20-8550-41d9-be33-a83b2a4e32a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully cleaned and wrapped the 'description' column!\n",
            "Cleaned data saved to: 'part_1_cleaned_and_wrapped.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPORTS\n"
      ],
      "metadata": {
        "id": "Q45V8jzEiClP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp,  regexp_extract,when, isnull, sum as _sum\n",
        "from pyspark.sql.types import ShortType\n",
        "from pyspark.sql.functions import col, when, count, desc, split, explode, regexp_extract, avg, round,countDistinct,trim,dense_rank\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "ATs7fusydb7b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Initialize a SparkSession"
      ],
      "metadata": {
        "id": "6R0AzaypiK7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"NetflixDataCleaning\").getOrCreate()"
      ],
      "metadata": {
        "id": "DpTYOZ_6iJGs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load the dataset"
      ],
      "metadata": {
        "id": "L-HWBpyiiZh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV with custom delimiter and escape handling\n",
        "\n",
        "df = spark.read.csv(\n",
        "    \"part_1_cleaned_and_wrapped.csv\",  # Or your latest fixed file\n",
        "    header=True,\n",
        "    sep=\",\",\n",
        "    quote='\"',\n",
        "    escape='\\\\',\n",
        "    multiLine=True,\n",
        "    mode=\"PERMISSIVE\"\n",
        ")\n",
        "\n",
        "# Print the schema to verify it's loaded correctly\n",
        "print(\"Original Schema:\")\n",
        "df.printSchema()\n",
        "\n",
        "df_t0 = df.withColumn(\n",
        "    \"description\",\n",
        "    regexp_extract(col(\"description\"), r\"\\$\\$\\$(.*?)\\$\\$\\$\", 1)\n",
        ").withColumn(\n",
        "    \"cast\",\n",
        "    regexp_extract(col(\"cast\"), r\"\\$\\$\\$(.*?)\\$\\$\\$\", 1)\n",
        ").withColumn(\n",
        "    \"listed_in\",\n",
        "    regexp_extract(col(\"listed_in\"), r\"\\$\\$\\$(.*?)\\$\\$\\$\", 1)\n",
        ").withColumn(\n",
        "    \"title\",\n",
        "    regexp_extract(col(\"title\"), r\"\\$\\$\\$(.*?)\\$\\$\\$\", 1)\n",
        ").withColumn(\n",
        "    \"director\",\n",
        "    regexp_extract(col(\"director\"), r\"\\$\\$\\$(.*?)\\$\\$\\$\", 1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec3LL8ZEiXmU",
        "outputId": "426f6f30-5442-444e-eda4-0cbe2097680b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Schema:\n",
            "root\n",
            " |-- show_id: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- director: string (nullable = true)\n",
            " |-- cast: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- date_added: string (nullable = true)\n",
            " |-- release_year: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- duration: string (nullable = true)\n",
            " |-- listed_in: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--- Data Cleaning ---**"
      ],
      "metadata": {
        "id": "RikRJilSk0lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Handle Missing Values"
      ],
      "metadata": {
        "id": "2WmP6J6sk4VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill 'director', 'cast', and 'country' with \"Unknown\"\n",
        "df_t1 = df_t0.na.fill(\"Unknown\", subset=['director', 'cast', 'country'])"
      ],
      "metadata": {
        "id": "ygioYEtZjqbD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'date_added' or 'rating' are null\n",
        "df_t2 = df_t1.na.drop(subset=['date_added', 'rating'])"
      ],
      "metadata": {
        "id": "D1gslkKBlExd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Correct Data Types"
      ],
      "metadata": {
        "id": "Rw-A8ad8lZgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date_added' from string to timestamp\n",
        "df_t3 = df_t2.withColumn(\n",
        "    \"date_added_ts\",\n",
        "    to_timestamp(col(\"date_added\"), \"MMMM d, yyyy\")\n",
        ").drop(\"date_added\").withColumnRenamed(\"date_added_ts\", \"date_added\")"
      ],
      "metadata": {
        "id": "h7VenaqllT0B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Remove Duplicates"
      ],
      "metadata": {
        "id": "HB_JWdLinN6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_t4 = df_t3.dropDuplicates()\n",
        "df_t4.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh9aypnEnC4l",
        "outputId": "76ae1d9f-841e-433b-8a5e-b22a959f3ffc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- show_id: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- director: string (nullable = false)\n",
            " |-- cast: string (nullable = false)\n",
            " |-- country: string (nullable = false)\n",
            " |-- release_year: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- duration: string (nullable = true)\n",
            " |-- listed_in: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- date_added: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--- Optimization ---**"
      ],
      "metadata": {
        "id": "ZzohokQZqbZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Optimize Data Types"
      ],
      "metadata": {
        "id": "OKi4muCFoOxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast 'release_year' to a smaller integer type (ShortType is like int16)\n",
        "df_t5 = df_t4.withColumn(\n",
        "    \"release_year\",\n",
        "    col(\"release_year\").cast(ShortType())\n",
        ")"
      ],
      "metadata": {
        "id": "XSBt3pmrnQs2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Save the Cleaned Data"
      ],
      "metadata": {
        "id": "neT9axn9ozX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_t5.coalesce(1).write.csv(\n",
        "    \"cleaned_netflix_spark_output\",\n",
        "    header=True,\n",
        "    mode=\"overwrite\" # Overwrites the directory if it exists\n",
        ")"
      ],
      "metadata": {
        "id": "HICe8J9joghQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of writing data with both partitioning and bucketing\n",
        "df_t5.write.partitionBy(\"type\", \"release_year\") \\\n",
        "    .bucketBy(16, \"show_id\") \\\n",
        "    .sortBy(\"show_id\") \\\n",
        "    .saveAsTable(\"netflix_optimized\")"
      ],
      "metadata": {
        "id": "B6w_64UnUC7f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's give it a clear name for this set of queries\n",
        "df = spark.table(\"netflix_optimized\")\n",
        "\n"
      ],
      "metadata": {
        "id": "eZSmoxQbd_nK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--- User Story ---**"
      ],
      "metadata": {
        "id": "dewVC_Tw0EE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. what type of movies has highest duration (more than 1 hr)? total number of movies of that type\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_z4OgPwpeqc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter movies with duration more than 60 minutes\n",
        "movies_over_60min = df.filter((col(\"type\") == \"Movie\") & (col(\"duration\").endswith(\"min\")))\n",
        "\n",
        "# Extract numeric duration and filter those greater than 60\n",
        "movies_over_60min = movies_over_60min.withColumn(\"duration_min\", split(col(\"duration\"), \" \").getItem(0).cast(\"int\"))\n",
        "movies_over_60min = movies_over_60min.filter(col(\"duration_min\") > 60)\n",
        "\n",
        "# Split 'listed_in' into individual genres and explode\n",
        "movies_exploded = movies_over_60min.withColumn(\"genre\", explode(split(col(\"listed_in\"), \", \")))\n",
        "\n",
        "# Group by genre and count\n",
        "genre_counts = movies_exploded.groupBy(\"genre\").count()\n",
        "\n",
        "# Find the genre with the highest count\n",
        "top_genre = genre_counts.orderBy(col(\"count\").desc()).limit(1)\n",
        "\n",
        "# Show the result\n",
        "top_genre.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkjWSfXT_jhs",
        "outputId": "1cc378f8-fbef-458a-8619-7c3211c07ae7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|               genre|count|\n",
            "+--------------------+-----+\n",
            "|International Movies| 2672|\n",
            "+--------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Which country has the highest tv shows, by show_id wise, with description."
      ],
      "metadata": {
        "id": "Xgf6wFpmfBqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows_df = df.filter(col(\"type\") == \"TV Show\")\n",
        "\n",
        "# Group by country and count distinct show_id\n",
        "country_tv_counts = tv_shows_df.groupBy(\"country\").agg(countDistinct(\"show_id\").alias(\"tv_show_count\"))\n",
        "\n",
        "# Find the country with the highest number of TV shows\n",
        "top_country = country_tv_counts.orderBy(desc(\"tv_show_count\")).first()[\"country\"]\n",
        "\n",
        "# Filter the TV shows from the top country\n",
        "top_country_tv_shows = tv_shows_df.filter(col(\"country\") == top_country).select(\"show_id\", \"title\", \"description\")\n",
        "\n",
        "# Show the result\n",
        "top_country, top_country_tv_shows.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "30G2uOaAd43_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized: 2. Query Which country has the highest tv shows, by show_id wise, with description."
      ],
      "metadata": {
        "id": "55-Bxqd24wF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a window to calculate the count of shows for each country\n",
        "country_window = Window.partitionBy(\"country\")\n",
        "\n",
        "# Add a column with the count of TV shows for each country\n",
        "tv_shows_with_counts = df.filter(col(\"type\") == \"TV Show\") \\\n",
        "                         .withColumn(\"tv_show_count\", count(\"show_id\").over(country_window))\n",
        "\n",
        "# Define a window to rank the countries based on their show count\n",
        "rank_window = Window.orderBy(desc(\"tv_show_count\"))\n",
        "\n",
        "# Add a rank column, filter for the top rank (rank=1), and select the final columns\n",
        "top_country_tv_shows = tv_shows_with_counts.withColumn(\"rank\", dense_rank().over(rank_window)) \\\n",
        "                                           .filter(col(\"rank\") == 1) \\\n",
        "                                           .select(\"show_id\", \"title\", \"description\")\n",
        "\n",
        "# Show the result. This is the only action, triggering a single, optimized job.\n",
        "top_country_tv_shows.show(truncate=False)\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "ZhpmgVGF4MLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. What type of movies released in 2021?"
      ],
      "metadata": {
        "id": "ERnaQirygyr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for movies released in 2021\n",
        "movies_2021 = df.filter((col(\"type\") == \"Movie\") & (col(\"release_year\") == 2021))\n",
        "\n",
        "# Select and get distinct movie types from 'listed_in'\n",
        "movie_types_2021 = movies_2021.select(\"listed_in\").distinct()\n",
        "\n",
        "# Show the result\n",
        "movie_types_2021.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "uuIdllmagxjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. In which country highest movies were released?"
      ],
      "metadata": {
        "id": "R7cwNv15k6Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only movies\n",
        "movies_df = df.filter(col(\"type\") == \"Movie\")\n",
        "\n",
        "# Split multiple countries and explode into separate rows\n",
        "movies_by_country = movies_df.withColumn(\"country\", explode(split(col(\"country\"), \",\")))\n",
        "\n",
        "# Trim whitespace from country names\n",
        "movies_by_country = movies_by_country.withColumn(\"country\", trim(col(\"country\")))\n",
        "\n",
        "# Group by country and count the number of movies\n",
        "country_movie_counts = movies_by_country.groupBy(\"country\").count()\n",
        "\n",
        "# Find the country with the highest number of movies\n",
        "top_country = country_movie_counts.orderBy(col(\"count\").desc()).first()\n",
        "\n",
        "\n",
        "print(top_country)"
      ],
      "metadata": {
        "id": "_ieodFAffQOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Which country has highest comedy movie category? And the total number of comedy movies, by show id."
      ],
      "metadata": {
        "id": "sh39Lrqbk-1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for comedy movies\n",
        "comedy_movies = df.filter(\n",
        "    (col(\"type\") == \"Movie\") &\n",
        "    (col(\"listed_in\").contains(\"Comedies\")) &\n",
        "    (col(\"country\").isNotNull())\n",
        ")\n",
        "\n",
        "# Group by country and count unique show_id\n",
        "comedy_count_by_country = comedy_movies.groupBy(\"country\").count()\n",
        "\n",
        "# Find the country with the highest number of comedy movies\n",
        "top_country = comedy_count_by_country.orderBy(col(\"count\").desc()).limit(1)\n",
        "\n",
        "# Show the result\n",
        "top_country.show()\n"
      ],
      "metadata": {
        "id": "4Yg_jHn3lAOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GQ-hONNUdBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}